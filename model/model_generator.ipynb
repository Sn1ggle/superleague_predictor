{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geladene Spalten: ['Season', 'Spieltag', 'Future', 'Rank', 'Team', 'Spiele', 'G', 'U', 'V', 'Tore', 'Goal_Diff', 'Points']\n",
      "Beispiel-Datensätze (Trainingsdaten):\n",
      "    Season  Spieltag  Future  Rank            Team  Spiele   G   U   V  Tore  \\\n",
      "0     2024        30   False     1        FC Basel      30  15   7   8  -1.0   \n",
      "1     2024        30   False     2     Servette FC      30  14   9   7  -1.0   \n",
      "2     2024        30   False     3  BSC Young Boys      30  14   7   9  -1.0   \n",
      "3     2024        30   False     4       FC Luzern      30  13   9   8  -1.0   \n",
      "4     2024        30   False     5       FC Lugano      30  14   6  10  -1.0   \n",
      "5     2024        30   False     6       FC Zürich      30  13   7  10  -1.0   \n",
      "6     2024        30   False     7  Lausanne-Sport      30  11   8  11  -1.0   \n",
      "7     2024        30   False     8   FC St. Gallen      30  10  10  10  -1.0   \n",
      "8     2024        30   False     9         FC Sion      30   9   8  13  -1.0   \n",
      "9     2024        30   False    10   Yverdon Sport      30   8   8  14  -1.0   \n",
      "10    2024        30   False    11    Grasshoppers      30   5  12  13  -1.0   \n",
      "11    2024        30   False    12   FC Winterthur      30   6   5  19  -1.0   \n",
      "12    2024        31   False     1        FC Basel      31  16   7   8  -1.0   \n",
      "13    2024        31   False     2     Servette FC      31  14   9   8  -1.0   \n",
      "14    2024        31   False     3  BSC Young Boys      31  14   8   9  -1.0   \n",
      "\n",
      "    Goal_Diff  Points  Restspiele  Estimated_Extra_Points  relegated  \n",
      "0        29.0    52.0           8                     9.6          0  \n",
      "1         9.0    51.0           8                     9.6          0  \n",
      "2        11.0    49.0           8                     9.6          0  \n",
      "3         8.0    48.0           8                     9.6          0  \n",
      "4         5.0    48.0           8                     9.6          0  \n",
      "5         1.0    46.0           8                     9.6          0  \n",
      "6         5.0    41.0           8                     9.6          0  \n",
      "7         1.0    40.0           8                     9.6          0  \n",
      "8        -7.0    35.0           8                     9.6          0  \n",
      "9       -18.0    32.0           8                     9.6          0  \n",
      "10      -13.0    27.0           8                     9.6          1  \n",
      "11      -31.0    23.0           8                     9.6          1  \n",
      "12       31.0    55.0           7                     8.4          0  \n",
      "13        8.0    51.0           7                     8.4          0  \n",
      "14       11.0    50.0           7                     8.4          0  \n",
      "Modell: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       119\n",
      "           1       0.54      1.00      0.70        13\n",
      "\n",
      "    accuracy                           0.92       132\n",
      "   macro avg       0.77      0.95      0.83       132\n",
      "weighted avg       0.95      0.92      0.93       132\n",
      "\n",
      "Accuracy: 0.9167 | F1-Score: 0.7027 | Brier Score Loss: 0.0476\n",
      "--------------------------------------------------\n",
      "Modell: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       119\n",
      "           1       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.96       132\n",
      "   macro avg       0.88      0.91      0.90       132\n",
      "weighted avg       0.96      0.96      0.96       132\n",
      "\n",
      "Accuracy: 0.9621 | F1-Score: 0.8148 | Brier Score Loss: 0.0266\n",
      "--------------------------------------------------\n",
      "Modell: Support Vector Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       119\n",
      "           1       0.50      1.00      0.67        13\n",
      "\n",
      "    accuracy                           0.90       132\n",
      "   macro avg       0.75      0.95      0.80       132\n",
      "weighted avg       0.95      0.90      0.92       132\n",
      "\n",
      "Accuracy: 0.9015 | F1-Score: 0.6667 | Brier Score Loss: 0.0183\n",
      "--------------------------------------------------\n",
      "Bestes Modell basierend auf F1-Score: Random Forest\n",
      "Bestes Modell und Skalierer wurden gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, brier_score_loss\n",
    "import joblib\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Daten aus MongoDB laden\n",
    "# -----------------------------------------------------------------------------\n",
    "# Aufbau der Verbindung zur MongoDB und Laden aller Dokumente aus der \"league-tables\" Collection\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\")\n",
    "if not mongodb_uri:\n",
    "    raise ValueError(\"Die Umgebungsvariable MONGODB_URI ist nicht gesetzt!\")\n",
    "\n",
    "client = MongoClient(mongodb_uri)\n",
    "db = client[\"mdm-project1\"]\n",
    "cursor = db[\"league-tables\"].find()\n",
    "df = pd.DataFrame(list(cursor))\n",
    "if '_id' in df.columns:\n",
    "    df.drop('_id', axis=1, inplace=True)\n",
    "print(\"Geladene Spalten:\", df.columns.tolist())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Datenvorbereitung\n",
    "# -----------------------------------------------------------------------------\n",
    "# Konvertiere relevante Spalten in numerische Werte\n",
    "numeric_cols = ['Spieltag', 'Rank', 'Spiele', 'G', 'U', 'V', 'Tore', 'Goal_Diff', 'Points']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fülle alle fehlenden Werte in den Spalten mit -1\n",
    "df.fillna(-1, inplace=True)\n",
    "\n",
    "# Filter: Für das Modelltraining werden nur bereits abgeschlossene Spieltage verwendet. \n",
    "# (Es wird angenommen, dass in der Spalte \"Future\" bereits ein boolescher Wert vorhanden ist.)\n",
    "df_train = df[df['Future'] == False].copy()\n",
    "\n",
    "# Berechne das Feature \"Restspiele\" (Differenz zur Saisonlänge von 38 Spieltagen), falls nicht vorhanden\n",
    "if 'Restspiele' not in df_train.columns:\n",
    "    df_train['Restspiele'] = 38 - df_train['Spieltag']\n",
    "\n",
    "# Berechne \"Estimated_Extra_Points\" als Schätzung (zum Beispiel 1.2 Punkte pro verbleibendem Spiel)\n",
    "if 'Estimated_Extra_Points' not in df_train.columns:\n",
    "    df_train['Estimated_Extra_Points'] = df_train['Restspiele'] * 1.2\n",
    "\n",
    "# Zielvariable: Ein Team gilt als gefährdet (relegated = 1), wenn der Rank entweder 11 oder 12 beträgt.\n",
    "df_train['relegated'] = df_train['Rank'].apply(lambda x: 1 if x in [11, 12] else 0)\n",
    "\n",
    "# Kontrolle der ersten Zeilen\n",
    "print(\"Beispiel-Datensätze (Trainingsdaten):\")\n",
    "print(df_train.head(15))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Trainingsdaten definieren und Feature-Vektor erstellen\n",
    "# -----------------------------------------------------------------------------\n",
    "# Die Feature-Matrix beinhaltet aktuelle Leistungsdaten und Zukunftsfeatures\n",
    "features = ['Points', 'Goal_Diff', 'G', 'U', 'V', 'Restspiele', 'Estimated_Extra_Points']\n",
    "X = df_train[features]\n",
    "y = df_train['relegated']\n",
    "\n",
    "# Sicherstellen, dass keine fehlenden Werte in den Features vorliegen\n",
    "assert X.isna().sum().sum() == 0, \"Es gibt noch NaN-Werte in den Features!\"\n",
    "\n",
    "# Aufteilen in Trainings- (80%) und Testdaten (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. Vorverarbeitung: Skalierung\n",
    "# -----------------------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. Modelltraining und Evaluation\n",
    "# -----------------------------------------------------------------------------\n",
    "# Drei Klassifikatoren werden mit der Option class_weight='balanced' trainiert, um der Klassenunbalance entgegenzuwirken.\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Support Vector Classifier': SVC(probability=True, class_weight='balanced')\n",
    "}\n",
    "\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    brier = brier_score_loss(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "    print(f\"Modell: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {acc:.4f} | F1-Score: {f1:.4f} | Brier Score Loss: {brier:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    model_scores[name] = {\"accuracy\": acc, \"f1\": f1, \"brier\": brier}\n",
    "\n",
    "# Auswahl des besten Modells basierend auf dem höchsten F1-Score\n",
    "best_model_name = max(model_scores, key=lambda k: model_scores[k]['f1'])\n",
    "print(f\"Bestes Modell basierend auf F1-Score: {best_model_name}\")\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. Persistierung\n",
    "# -----------------------------------------------------------------------------\n",
    "# Speichern des besten Modells und des Skalierers für den späteren Einsatz (z.B. im Flask-Service)\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Bestes Modell und Skalierer wurden gespeichert.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
